{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mendesain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "tensor([[2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [3], [4], [5]], dtype=torch.float32)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    }
   ],
   "source": [
    "input_size = n_features\n",
    "output_size = n_features\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Awal: -22.65580177307129\n"
     ]
    }
   ],
   "source": [
    "# Desain model\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "X_test = torch.tensor([[25]], dtype=torch.float32)\n",
    "print(f\"Prediksi Awal: {model(X_test).item()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merancang Loss dan Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(x):\n",
    "#     return x * w\n",
    "\n",
    "# Menggunakan loss function dari torch\n",
    "loss = nn.MSELoss()     # Mean Squared Error Loss\n",
    "\n",
    "# Menggunakan optimizer dari torch\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)       # Stochastic Gradient Descent optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/6000\n",
      "Weight: -0.8848255276679993\n",
      "Bias  : 0.2855175733566284\n",
      "Loss  : 35.04899597167969\n",
      "\n",
      "Epoch : 51/6000\n",
      "Weight: 0.20039916038513184\n",
      "Bias  : 0.655717134475708\n",
      "Loss  : 6.505645751953125\n",
      "\n",
      "Epoch : 101/6000\n",
      "Weight: 0.6677432656288147\n",
      "Bias  : 0.8157458305358887\n",
      "Loss  : 1.2079964876174927\n",
      "\n",
      "Epoch : 151/6000\n",
      "Weight: 0.8688993453979492\n",
      "Bias  : 0.885222315788269\n",
      "Loss  : 0.2247387170791626\n",
      "\n",
      "Epoch : 201/6000\n",
      "Weight: 0.9553810954093933\n",
      "Bias  : 0.9156797528266907\n",
      "Loss  : 0.04223055765032768\n",
      "\n",
      "Epoch : 251/6000\n",
      "Weight: 0.9924623370170593\n",
      "Bias  : 0.9293193221092224\n",
      "Loss  : 0.008341752924025059\n",
      "\n",
      "Epoch : 301/6000\n",
      "Weight: 1.0082637071609497\n",
      "Bias  : 0.935705840587616\n",
      "Loss  : 0.002037182217463851\n",
      "\n",
      "Epoch : 351/6000\n",
      "Weight: 1.0149002075195312\n",
      "Bias  : 0.9389601945877075\n",
      "Loss  : 0.0008526082965545356\n",
      "\n",
      "Epoch : 401/6000\n",
      "Weight: 1.0175907611846924\n",
      "Bias  : 0.9408575296401978\n",
      "Loss  : 0.0006187648396007717\n",
      "\n",
      "Epoch : 451/6000\n",
      "Weight: 1.0185840129852295\n",
      "Bias  : 0.9421631693840027\n",
      "Loss  : 0.0005617743008770049\n",
      "\n",
      "Epoch : 501/6000\n",
      "Weight: 1.018847942352295\n",
      "Bias  : 0.943206250667572\n",
      "Loss  : 0.0005380150978453457\n",
      "\n",
      "Epoch : 551/6000\n",
      "Weight: 1.018800973892212\n",
      "Bias  : 0.9441295266151428\n",
      "Loss  : 0.0005208089714869857\n",
      "\n",
      "Epoch : 601/6000\n",
      "Weight: 1.0186219215393066\n",
      "Bias  : 0.944993793964386\n",
      "Loss  : 0.0005052017513662577\n",
      "\n",
      "Epoch : 651/6000\n",
      "Weight: 1.0183883905410767\n",
      "Bias  : 0.9458259344100952\n",
      "Loss  : 0.0004902492510154843\n",
      "\n",
      "Epoch : 701/6000\n",
      "Weight: 1.0181337594985962\n",
      "Bias  : 0.9466372728347778\n",
      "Loss  : 0.00047578164958395064\n",
      "\n",
      "Epoch : 751/6000\n",
      "Weight: 1.0178714990615845\n",
      "Bias  : 0.9474331140518188\n",
      "Loss  : 0.0004617364320438355\n",
      "\n",
      "Epoch : 801/6000\n",
      "Weight: 1.0176092386245728\n",
      "Bias  : 0.948215663433075\n",
      "Loss  : 0.00044811455882154405\n",
      "\n",
      "Epoch : 851/6000\n",
      "Weight: 1.0173500776290894\n",
      "Bias  : 0.9489858150482178\n",
      "Loss  : 0.0004348976071923971\n",
      "\n",
      "Epoch : 901/6000\n",
      "Weight: 1.0170937776565552\n",
      "Bias  : 0.949743926525116\n",
      "Loss  : 0.00042207282967865467\n",
      "\n",
      "Epoch : 951/6000\n",
      "Weight: 1.0168397426605225\n",
      "Bias  : 0.9504905939102173\n",
      "Loss  : 0.0004096261691302061\n",
      "\n",
      "Epoch : 1001/6000\n",
      "Weight: 1.0165894031524658\n",
      "Bias  : 0.9512261152267456\n",
      "Loss  : 0.0003975448780693114\n",
      "\n",
      "Epoch : 1051/6000\n",
      "Weight: 1.016343593597412\n",
      "Bias  : 0.9519508481025696\n",
      "Loss  : 0.000385818537324667\n",
      "\n",
      "Epoch : 1101/6000\n",
      "Weight: 1.0161000490188599\n",
      "Bias  : 0.9526646733283997\n",
      "Loss  : 0.000374439696315676\n",
      "\n",
      "Epoch : 1151/6000\n",
      "Weight: 1.0158616304397583\n",
      "Bias  : 0.9533678293228149\n",
      "Loss  : 0.00036340043880045414\n",
      "\n",
      "Epoch : 1201/6000\n",
      "Weight: 1.0156258344650269\n",
      "Bias  : 0.9540606737136841\n",
      "Loss  : 0.00035267879138700664\n",
      "\n",
      "Epoch : 1251/6000\n",
      "Weight: 1.0153933763504028\n",
      "Bias  : 0.9547430872917175\n",
      "Loss  : 0.00034227975993417203\n",
      "\n",
      "Epoch : 1301/6000\n",
      "Weight: 1.0151653289794922\n",
      "Bias  : 0.9554154872894287\n",
      "Loss  : 0.0003321894910186529\n",
      "\n",
      "Epoch : 1351/6000\n",
      "Weight: 1.0149388313293457\n",
      "Bias  : 0.9560778737068176\n",
      "Loss  : 0.0003223855164833367\n",
      "\n",
      "Epoch : 1401/6000\n",
      "Weight: 1.0147181749343872\n",
      "Bias  : 0.956730306148529\n",
      "Loss  : 0.0003128839307464659\n",
      "\n",
      "Epoch : 1451/6000\n",
      "Weight: 1.0144987106323242\n",
      "Bias  : 0.9573730826377869\n",
      "Loss  : 0.00030365417478606105\n",
      "\n",
      "Epoch : 1501/6000\n",
      "Weight: 1.0142841339111328\n",
      "Bias  : 0.9580062627792358\n",
      "Loss  : 0.0002947005850728601\n",
      "\n",
      "Epoch : 1551/6000\n",
      "Weight: 1.0140714645385742\n",
      "Bias  : 0.9586302042007446\n",
      "Loss  : 0.0002860071836039424\n",
      "\n",
      "Epoch : 1601/6000\n",
      "Weight: 1.0138628482818604\n",
      "Bias  : 0.9592447280883789\n",
      "Loss  : 0.0002775761531665921\n",
      "\n",
      "Epoch : 1651/6000\n",
      "Weight: 1.0136566162109375\n",
      "Bias  : 0.9598503112792969\n",
      "Loss  : 0.00026938816881738603\n",
      "\n",
      "Epoch : 1701/6000\n",
      "Weight: 1.0134539604187012\n",
      "Bias  : 0.9604466557502747\n",
      "Loss  : 0.0002614461409393698\n",
      "\n",
      "Epoch : 1751/6000\n",
      "Weight: 1.0132540464401245\n",
      "Bias  : 0.9610342979431152\n",
      "Loss  : 0.0002537330728955567\n",
      "\n",
      "Epoch : 1801/6000\n",
      "Weight: 1.0130573511123657\n",
      "Bias  : 0.9616129994392395\n",
      "Loss  : 0.00024625318474136293\n",
      "\n",
      "Epoch : 1851/6000\n",
      "Weight: 1.0128631591796875\n",
      "Bias  : 0.9621832966804504\n",
      "Loss  : 0.0002389904111623764\n",
      "\n",
      "Epoch : 1901/6000\n",
      "Weight: 1.0126724243164062\n",
      "Bias  : 0.962744951248169\n",
      "Loss  : 0.00023194676032289863\n",
      "\n",
      "Epoch : 1951/6000\n",
      "Weight: 1.0124837160110474\n",
      "Bias  : 0.963298499584198\n",
      "Loss  : 0.00022510034614242613\n",
      "\n",
      "Epoch : 2001/6000\n",
      "Weight: 1.0122989416122437\n",
      "Bias  : 0.9638436436653137\n",
      "Loss  : 0.00021846759773325175\n",
      "\n",
      "Epoch : 2051/6000\n",
      "Weight: 1.012115240097046\n",
      "Bias  : 0.96438068151474\n",
      "Loss  : 0.00021202101197559386\n",
      "\n",
      "Epoch : 2101/6000\n",
      "Weight: 1.0119364261627197\n",
      "Bias  : 0.9649097323417664\n",
      "Loss  : 0.0002057727542705834\n",
      "\n",
      "Epoch : 2151/6000\n",
      "Weight: 1.0117576122283936\n",
      "Bias  : 0.9654310345649719\n",
      "Loss  : 0.00019970108405686915\n",
      "\n",
      "Epoch : 2201/6000\n",
      "Weight: 1.0115845203399658\n",
      "Bias  : 0.9659444689750671\n",
      "Loss  : 0.00019381845777388662\n",
      "\n",
      "Epoch : 2251/6000\n",
      "Weight: 1.0114116668701172\n",
      "Bias  : 0.9664503931999207\n",
      "Loss  : 0.00018809914763551205\n",
      "\n",
      "Epoch : 2301/6000\n",
      "Weight: 1.0112427473068237\n",
      "Bias  : 0.9669486880302429\n",
      "Loss  : 0.00018255664326716214\n",
      "\n",
      "Epoch : 2351/6000\n",
      "Weight: 1.0110758543014526\n",
      "Bias  : 0.9674395322799683\n",
      "Loss  : 0.00017717316222842783\n",
      "\n",
      "Epoch : 2401/6000\n",
      "Weight: 1.0109106302261353\n",
      "Bias  : 0.967923104763031\n",
      "Loss  : 0.0001719481952022761\n",
      "\n",
      "Epoch : 2451/6000\n",
      "Weight: 1.0107496976852417\n",
      "Bias  : 0.9683995246887207\n",
      "Loss  : 0.00016688293544575572\n",
      "\n",
      "Epoch : 2501/6000\n",
      "Weight: 1.0105887651443481\n",
      "Bias  : 0.9688687920570374\n",
      "Loss  : 0.00016196031356230378\n",
      "\n",
      "Epoch : 2551/6000\n",
      "Weight: 1.0104326009750366\n",
      "Bias  : 0.9693312048912048\n",
      "Loss  : 0.0001571869506733492\n",
      "\n",
      "Epoch : 2601/6000\n",
      "Weight: 1.0102776288986206\n",
      "Bias  : 0.9697865843772888\n",
      "Loss  : 0.0001525537227280438\n",
      "\n",
      "Epoch : 2651/6000\n",
      "Weight: 1.0101240873336792\n",
      "Bias  : 0.9702355265617371\n",
      "Loss  : 0.00014805242244619876\n",
      "\n",
      "Epoch : 2701/6000\n",
      "Weight: 1.0099750757217407\n",
      "Bias  : 0.970677375793457\n",
      "Loss  : 0.0001436929451301694\n",
      "\n",
      "Epoch : 2751/6000\n",
      "Weight: 1.0098260641098022\n",
      "Bias  : 0.9711127281188965\n",
      "Loss  : 0.0001394530845573172\n",
      "\n",
      "Epoch : 2801/6000\n",
      "Weight: 1.0096803903579712\n",
      "Bias  : 0.9715418815612793\n",
      "Loss  : 0.00013534104800783098\n",
      "\n",
      "Epoch : 2851/6000\n",
      "Weight: 1.0095373392105103\n",
      "Bias  : 0.971964418888092\n",
      "Loss  : 0.0001313534885412082\n",
      "\n",
      "Epoch : 2901/6000\n",
      "Weight: 1.0093942880630493\n",
      "Bias  : 0.9723806381225586\n",
      "Loss  : 0.00012748007429763675\n",
      "\n",
      "Epoch : 2951/6000\n",
      "Weight: 1.0092558860778809\n",
      "Bias  : 0.9727910161018372\n",
      "Loss  : 0.00012372122728265822\n",
      "\n",
      "Epoch : 3001/6000\n",
      "Weight: 1.0091187953948975\n",
      "Bias  : 0.9731948971748352\n",
      "Loss  : 0.00012007874465780333\n",
      "\n",
      "Epoch : 3051/6000\n",
      "Weight: 1.008981704711914\n",
      "Bias  : 0.9735928773880005\n",
      "Loss  : 0.00011653453839244321\n",
      "\n",
      "Epoch : 3101/6000\n",
      "Weight: 1.008849859237671\n",
      "Bias  : 0.9739851951599121\n",
      "Loss  : 0.00011310275294817984\n",
      "\n",
      "Epoch : 3151/6000\n",
      "Weight: 1.008718729019165\n",
      "Bias  : 0.9743712544441223\n",
      "Loss  : 0.00010976861813105643\n",
      "\n",
      "Epoch : 3201/6000\n",
      "Weight: 1.0085875988006592\n",
      "Bias  : 0.9747517108917236\n",
      "Loss  : 0.00010653218487277627\n",
      "\n",
      "Epoch : 3251/6000\n",
      "Weight: 1.0084614753723145\n",
      "Bias  : 0.9751267433166504\n",
      "Loss  : 0.00010339215805288404\n",
      "\n",
      "Epoch : 3301/6000\n",
      "Weight: 1.0083363056182861\n",
      "Bias  : 0.9754958748817444\n",
      "Loss  : 0.00010034874139819294\n",
      "\n",
      "Epoch : 3351/6000\n",
      "Weight: 1.0082111358642578\n",
      "Bias  : 0.9758597016334534\n",
      "Loss  : 9.73866117419675e-05\n",
      "\n",
      "Epoch : 3401/6000\n",
      "Weight: 1.0080900192260742\n",
      "Bias  : 0.9762183427810669\n",
      "Loss  : 9.451476216781884e-05\n",
      "\n",
      "Epoch : 3451/6000\n",
      "Weight: 1.0079708099365234\n",
      "Bias  : 0.9765713810920715\n",
      "Loss  : 9.17330471565947e-05\n",
      "\n",
      "Epoch : 3501/6000\n",
      "Weight: 1.0078516006469727\n",
      "Bias  : 0.9769188761711121\n",
      "Loss  : 8.902966510504484e-05\n",
      "\n",
      "Epoch : 3551/6000\n",
      "Weight: 1.0077342987060547\n",
      "Bias  : 0.9772617816925049\n",
      "Loss  : 8.640156738692895e-05\n",
      "\n",
      "Epoch : 3601/6000\n",
      "Weight: 1.0076210498809814\n",
      "Bias  : 0.9775993824005127\n",
      "Loss  : 8.386043919017538e-05\n",
      "\n",
      "Epoch : 3651/6000\n",
      "Weight: 1.0075078010559082\n",
      "Bias  : 0.9779316782951355\n",
      "Loss  : 8.138883276842535e-05\n",
      "\n",
      "Epoch : 3701/6000\n",
      "Weight: 1.007394552230835\n",
      "Bias  : 0.978259265422821\n",
      "Loss  : 7.898831972852349e-05\n",
      "\n",
      "Epoch : 3751/6000\n",
      "Weight: 1.0072861909866333\n",
      "Bias  : 0.9785823225975037\n",
      "Loss  : 7.666123565286398e-05\n",
      "\n",
      "Epoch : 3801/6000\n",
      "Weight: 1.0071789026260376\n",
      "Bias  : 0.9788998961448669\n",
      "Loss  : 7.440625631716102e-05\n",
      "\n",
      "Epoch : 3851/6000\n",
      "Weight: 1.007071614265442\n",
      "Bias  : 0.9792129993438721\n",
      "Loss  : 7.2211361839436e-05\n",
      "\n",
      "Epoch : 3901/6000\n",
      "Weight: 1.006965160369873\n",
      "Bias  : 0.979521632194519\n",
      "Loss  : 7.008125248830765e-05\n",
      "\n",
      "Epoch : 3951/6000\n",
      "Weight: 1.0068635940551758\n",
      "Bias  : 0.9798256754875183\n",
      "Loss  : 6.80198281770572e-05\n",
      "\n",
      "Epoch : 4001/6000\n",
      "Weight: 1.0067622661590576\n",
      "Bias  : 0.9801250100135803\n",
      "Loss  : 6.601722270715982e-05\n",
      "\n",
      "Epoch : 4051/6000\n",
      "Weight: 1.0066609382629395\n",
      "Bias  : 0.9804198145866394\n",
      "Loss  : 6.40702637610957e-05\n",
      "\n",
      "Epoch : 4101/6000\n",
      "Weight: 1.0065609216690063\n",
      "Bias  : 0.9807106256484985\n",
      "Loss  : 6.217904592631385e-05\n",
      "\n",
      "Epoch : 4151/6000\n",
      "Weight: 1.006465196609497\n",
      "Bias  : 0.9809970855712891\n",
      "Loss  : 6.0349917475832626e-05\n",
      "\n",
      "Epoch : 4201/6000\n",
      "Weight: 1.0063698291778564\n",
      "Bias  : 0.9812788367271423\n",
      "Loss  : 5.857474752701819e-05\n",
      "\n",
      "Epoch : 4251/6000\n",
      "Weight: 1.0062744617462158\n",
      "Bias  : 0.98155677318573\n",
      "Loss  : 5.6847107771318406e-05\n",
      "\n",
      "Epoch : 4301/6000\n",
      "Weight: 1.0061795711517334\n",
      "Bias  : 0.9818305969238281\n",
      "Loss  : 5.5168136896099895e-05\n",
      "\n",
      "Epoch : 4351/6000\n",
      "Weight: 1.006089687347412\n",
      "Bias  : 0.9821003675460815\n",
      "Loss  : 5.354592212825082e-05\n",
      "\n",
      "Epoch : 4401/6000\n",
      "Weight: 1.006000280380249\n",
      "Bias  : 0.9823659062385559\n",
      "Loss  : 5.197031714487821e-05\n",
      "\n",
      "Epoch : 4451/6000\n",
      "Weight: 1.005910873413086\n",
      "Bias  : 0.9826272130012512\n",
      "Loss  : 5.0441034545656294e-05\n",
      "\n",
      "Epoch : 4501/6000\n",
      "Weight: 1.0058214664459229\n",
      "Bias  : 0.9828850030899048\n",
      "Loss  : 4.895243910141289e-05\n",
      "\n",
      "Epoch : 4551/6000\n",
      "Weight: 1.0057353973388672\n",
      "Bias  : 0.9831395149230957\n",
      "Loss  : 4.750633888761513e-05\n",
      "\n",
      "Epoch : 4601/6000\n",
      "Weight: 1.0056517124176025\n",
      "Bias  : 0.9833896160125732\n",
      "Loss  : 4.6110915718600154e-05\n",
      "\n",
      "Epoch : 4651/6000\n",
      "Weight: 1.005568265914917\n",
      "Bias  : 0.9836357831954956\n",
      "Loss  : 4.4755324779544026e-05\n",
      "\n",
      "Epoch : 4701/6000\n",
      "Weight: 1.0054848194122314\n",
      "Bias  : 0.9838784337043762\n",
      "Loss  : 4.343514592619613e-05\n",
      "\n",
      "Epoch : 4751/6000\n",
      "Weight: 1.005401372909546\n",
      "Bias  : 0.9841178059577942\n",
      "Loss  : 4.2153424146818e-05\n",
      "\n",
      "Epoch : 4801/6000\n",
      "Weight: 1.0053225755691528\n",
      "Bias  : 0.9843540191650391\n",
      "Loss  : 4.091056689503603e-05\n",
      "\n",
      "Epoch : 4851/6000\n",
      "Weight: 1.0052449703216553\n",
      "Bias  : 0.9845858812332153\n",
      "Loss  : 3.970889883930795e-05\n",
      "\n",
      "Epoch : 4901/6000\n",
      "Weight: 1.0051674842834473\n",
      "Bias  : 0.9848142266273499\n",
      "Loss  : 3.854156966554001e-05\n",
      "\n",
      "Epoch : 4951/6000\n",
      "Weight: 1.0050899982452393\n",
      "Bias  : 0.9850392937660217\n",
      "Loss  : 3.740649844985455e-05\n",
      "\n",
      "Epoch : 5001/6000\n",
      "Weight: 1.0050125122070312\n",
      "Bias  : 0.9852613806724548\n",
      "Loss  : 3.630110586527735e-05\n",
      "\n",
      "Epoch : 5051/6000\n",
      "Weight: 1.0049391984939575\n",
      "Bias  : 0.9854804277420044\n",
      "Loss  : 3.523108171066269e-05\n",
      "\n",
      "Epoch : 5101/6000\n",
      "Weight: 1.0048673152923584\n",
      "Bias  : 0.9856959581375122\n",
      "Loss  : 3.419533823034726e-05\n",
      "\n",
      "Epoch : 5151/6000\n",
      "Weight: 1.004795789718628\n",
      "Bias  : 0.9859079718589783\n",
      "Loss  : 3.319017923786305e-05\n",
      "\n",
      "Epoch : 5201/6000\n",
      "Weight: 1.0047242641448975\n",
      "Bias  : 0.9861167669296265\n",
      "Loss  : 3.221329825464636e-05\n",
      "\n",
      "Epoch : 5251/6000\n",
      "Weight: 1.004652738571167\n",
      "Bias  : 0.9863225817680359\n",
      "Loss  : 3.126318915747106e-05\n",
      "\n",
      "Epoch : 5301/6000\n",
      "Weight: 1.0045827627182007\n",
      "Bias  : 0.9865257143974304\n",
      "Loss  : 3.0340548619278707e-05\n",
      "\n",
      "Epoch : 5351/6000\n",
      "Weight: 1.0045160055160522\n",
      "Bias  : 0.986725926399231\n",
      "Loss  : 2.944675179605838e-05\n",
      "\n",
      "Epoch : 5401/6000\n",
      "Weight: 1.0044503211975098\n",
      "Bias  : 0.9869228005409241\n",
      "Loss  : 2.858154766727239e-05\n",
      "\n",
      "Epoch : 5451/6000\n",
      "Weight: 1.0043847560882568\n",
      "Bias  : 0.9871164560317993\n",
      "Loss  : 2.7741276426240802e-05\n",
      "\n",
      "Epoch : 5501/6000\n",
      "Weight: 1.004319190979004\n",
      "Bias  : 0.9873071908950806\n",
      "Loss  : 2.6925299607682973e-05\n",
      "\n",
      "Epoch : 5551/6000\n",
      "Weight: 1.004253625869751\n",
      "Bias  : 0.9874952435493469\n",
      "Loss  : 2.6132422135560773e-05\n",
      "\n",
      "Epoch : 5601/6000\n",
      "Weight: 1.0041897296905518\n",
      "Bias  : 0.9876810908317566\n",
      "Loss  : 2.5360692234244198e-05\n",
      "\n",
      "Epoch : 5651/6000\n",
      "Weight: 1.0041286945343018\n",
      "Bias  : 0.987864077091217\n",
      "Loss  : 2.4614098947495222e-05\n",
      "\n",
      "Epoch : 5701/6000\n",
      "Weight: 1.0040687322616577\n",
      "Bias  : 0.988044023513794\n",
      "Loss  : 2.3890675947768614e-05\n",
      "\n",
      "Epoch : 5751/6000\n",
      "Weight: 1.0040091276168823\n",
      "Bias  : 0.9882209897041321\n",
      "Loss  : 2.318894439667929e-05\n",
      "\n",
      "Epoch : 5801/6000\n",
      "Weight: 1.003949522972107\n",
      "Bias  : 0.9883952736854553\n",
      "Loss  : 2.2508182155434042e-05\n",
      "\n",
      "Epoch : 5851/6000\n",
      "Weight: 1.0038899183273315\n",
      "Bias  : 0.9885673522949219\n",
      "Loss  : 2.1844369257451035e-05\n",
      "\n",
      "Epoch : 5901/6000\n",
      "Weight: 1.0038303136825562\n",
      "Bias  : 0.9887372255325317\n",
      "Loss  : 2.1197662135818973e-05\n",
      "\n",
      "Epoch : 5951/6000\n",
      "Weight: 1.0037739276885986\n",
      "Bias  : 0.988904595375061\n",
      "Loss  : 2.0573103029164486e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 6000\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # forward pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # backward pass\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # gradients\n",
    "    l.backward()\n",
    "\n",
    "    # Memperbaharui weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Menghapus gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Menyimpan bias dan weights\n",
    "    [w, b] = model.parameters()\n",
    "\n",
    "    # mencetak nilai weight, bias, dan loss dengan progress bar\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch : {epoch+1}/{n_iters}\")\n",
    "        print(f\"Weight: {w.item()}\")\n",
    "        print(f\"Bias  : {b.item()}\")\n",
    "        print(f\"Loss  : {l.item()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Akhir: tensor([[26.0821]], grad_fn=<AddmmBackward0>)\n",
      "Prediksi Akhir: 26.082069396972656\n"
     ]
    }
   ],
   "source": [
    "# Prediksi setelah training\n",
    "print(f\"Prediksi Akhir: {model(X_test)}\")\n",
    "print(f\"Prediksi Akhir: {model(X_test).item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
